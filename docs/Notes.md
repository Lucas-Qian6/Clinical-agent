<!--
Tip: keep it scannable. One strong header, one punchy subtitle, then quick links.
-->
<h1 align="center">Emotion-based Clinical Agent</h1>
<p align="center">
  Dectect emotion -> Reinforce Learning -> LLM judge
</p>


 ğŸ¯ Background
- We want to create a clinical agent that understands human emotion, mood and sentiment in a deeply parameterized manner.
- **Potential Strategy:** Mapping human "states" into embeddings. It provides a representation layer that allows for vectorization and directionality in terms of modifying human behavior and modulating the human condition.

 ğŸ”¬ Market Research
 - Oracle Healthâ€™s Clinical AI Agent is focused on streamlining / augmenting existing clinical workflows in a broad sense. The focus is on integration into workflows leveraging EHRs and focuses on things like charting, documentation, and medication and order management. 

 ğŸ§° Stack
- API: `ChatGPT`, `Gemini`, `Huggingface`
- Torch
- Colab


 ğŸ§­ What We did
**10/2025 - 01/2026**
- **Aim:** Research on how to map discrete emotion classification `GoEmotion` into continuous values.
- 1) For a single sentence, used generative model `SamLowe/roberta-base-go_emotions` (Teacher Model) to get 28 emotion probabilities.
  2) Clinical interpretable look-up table: a fixed valence weight for each emotion `v`.
  3) Computed score = p * v for each emotion.
  4) Used MPNet `all-mpnet-base-v2` to score into 784-d vector.
  5) Trained models to predict the valence scores.
- Found `Hourglass model`, using 4-dimenstion to descirbe each emotion.

**01/2026 - 02/2026**
- **Aim:** Synthesize the dataset and make small benchmark using DPO.
- Start with DPO trainer since it's the simplest.
- 1) Found `MentalChat16K` dataset, which contains single turn: Patient - Therapist.
  2) Used `Gemini-2-flash` to generate clinically bad responses.
  3) Implemented `Weaver` (ensemble of weak verifiers) to filter our low-quanlity bad responses: 
  - Checks Semantic Consistency with Gold Standard: `mental/mental-bert-base-uncased`
  - Checks for warmth, empathy, and lack of judgment: `hadresh-savani/bert-base-uncased-emotion`
  - Checks if it's safety, leading users to suicide: `unitary/unbiased-toxic-roberta`
  - Checks adherence to CBT protocols (Heuristic): `Clinical_Protocol`
  - Checks Logical Coherence: `cross-encoder/ms-marco-MiniLM-L-6-v2`
  4) Got 500 data and trained the `unsloth/llama-3-8b-instruct-bnb-4bit`, using peft_model to decrease the amount of learnable parameters.
  5) Evaluate using the `Weaver`.

**02/2026 - Present**
- **Aim:** Set up the benchmark using DPO
- Found look-up table in research of using `SenticNet` to map Goemotion to Hourglass model.
- Existing emotion detection models classify emotions into 28 dimension `GoEmotion`.
- Use `bhadresh-savani/bert-base-go-emotion` to detect emotions from patient's sentence and used look-up table to transfer them into Hourglass dimensions.
- Found `Psychotherapy-LLM/PsychoCounsel-Preference`, an existing clinical dataset for training DPO models. So I detected and added emotions vectors to each row of this dataset.
- Trained on the same dataset above, `Psychotherapy-LLM/PsychoCounsel-Llama3-8B` becomes my baseline model. Their paper also reveal that we can use LLM like `ChatGPT`  as judge when evaluating the performance
- `TraitBasis` uses activations in the model to recognize human traits (emotions). 
So I added an emotional layer to the pre-trained model `Llama3-8B` and trained it using the same dataset.
**Problems:** Trained model's winning rate is only 5%. And it seems since I wrapped the model with peft mode, it only updated a few learnable parameters, and omit other parameters including my customized layers.

**Found:** Small language models (SLMs) + test-time scaling (TTS) + verification > large language models (LLMs).

**What I tried**
- Steps:
  1. â€¦
  2. â€¦
  3. â€¦
**What failed**
- Error: `...`
- Symptom: â€œ...â€
- Root cause (in one sentence): â€¦
**Fix**
- Change: â€¦
- Why it works: â€¦
**Takeaway**
- âœ… â€¦
- âŒ â€¦
 Attempt 2 â€” â€œDockerize earlyâ€
(Repeat the same pattern)
 ğŸš€ Setup
 Prereqs
- `docker` + `docker compose`
- `node` / `python` / `java`
- (Optional) `make`
 Quickstart
cp .env.example .env
docker compose up --build
Verify
- Open http://localhost:3000/health
- Expect: {"status":"ok"}
ğŸ§¯ Debug Notes
| Problem | Symptom | Fix |
|---|---|---|
| DB connection refused | API keeps restarting | Check compose network + correct DATABASE_URL |
| JWT invalid | 401 on refresh | Verify signing key + clock drift |
ğŸ—ºï¸ Next Steps
- [ ] Add rate limiting
- [ ] Add structured logging + trace IDs
- [ ] Add CI (tests + lint)
- [ ] Deploy + run a load test
ğŸ“„ License
MIT
Where to get â€œnice-looking iconsâ€
- Use Shields badges (fastest): `https://shields.io/`
- Use simple section icons (emoji) in headers like `âœ¨ ğŸ¯ ğŸ§° ğŸ§­ ğŸš€ ğŸ§¯ ğŸ—ºï¸` (works everywhere)
Where to get pretty images
- Diagrams: Excalidraw, draw.io, Figma
- Screenshots: clean terminal theme + crop + consistent width
- GIFs: `ffmpeg` / `peek` / `kap` (Mac) / ScreenToGif (Windows)
---
**2) â€œStory-styleâ€ template (good for Zhihu / Medium)**
```md
# I Built a Backend From Scratch â€” Hereâ€™s the Ugly Truth (and the Fixes)
> I documented every wrong turn on purpose, because thatâ€™s where the learning was.
## 0. What I was trying to build
- Goal:
- Constraints:
- Success criteria:
## 1. My first idea (and why it felt right)
- Reasoning:
- What I expected to happen:
## 2. First failure
**Symptom**
- â€¦
**What I tried**
1) â€¦
2) â€¦
3) â€¦
**What I searched**
- Keywords I used:
  - "..."
  - "..."
- The one concept I didnâ€™t understand yet:
  - â€¦
**Root cause**
- One sentence:
**Fix**
- â€¦
**Lesson**
- â€¦
## 3. Second failure (repeat)
â€¦
## 4. The final working approach
- What changed:
- Why it worked:
- Trade-offs:
## 5. What Iâ€™d do next
1) â€¦
2) â€¦
3) â€¦
## Appendix: Commands / Config snippets
```bash
# â€¦
---
**3) â€œNice wordsâ€ mini-phrases (use these in headings)**
- â€œWhat I believed vs what was trueâ€
- â€œThe moment it brokeâ€
- â€œThe real root causeâ€
- â€œThe fix that finally stuckâ€
- â€œTrade-offs I acceptedâ€
- â€œIf I restarted todayâ€
---
**4) Enumerations that look good**
- Use â€œshort lead + detailâ€ pattern:
  1) Bold lead: explanation.
  2) Bold lead: explanation.
- Use checklists for roadmap:
  - [ ] add CI
  - [ ] add metrics
- Use tables for common issues (very readable).
---
**5) Special symbols / separators (pick 1 style and stick to it)**
- Section dividers: `---` or `***`
- Callouts (simple, clean):
  - `Note:` â€¦
  - `Pitfall:` â€¦
  - `Rule:` â€¦
- Unicode symbols (use sparingly):
  - Arrows: `â†’` `â†³`
  - Checks: `âœ“` `âœ—`
  - Bullets: `â€¢` `Â·`
  - Emphasis: `â€”` (em dash), `â€¦`
  - Brackets: `ã€ã€‘` (CN style)
---